# Titanic-Machine-Learning-from-Disaster
**Overview**
In this project, we aimed to build a robust predictive model by analyzing a dataset to uncover patterns and insights about the survivors. Our process involved meticulous data preprocessing, feature engineering, and model selection to ensure the highest accuracy possible.

**Data Preprocessing**
Our initial step was to clean and prepare the data for analysis. We:
-Identified and dropped unnecessary features<br>
-Filled in missing values<br>
-Added new relevant features<br>
-This preprocessing ensured that our dataset was complete and ready for effective modeling.

**Feature Engineering**
We then focused on enhancing our dataset through feature engineering. By analyzing the data and leveraging insights from influential notebooks and visualizations, we discovered and added features that significantly improved our model's accuracy.

**Model Selection and Evaluation**
To find the best-performing model, we tested various algorithms. After rigorous evaluation, we determined that the SGDClassifier was the most effective for our dataset. This model stood out due to its high accuracy in making predictions based on the engineered features and patterns we identified.

**Final Model**
Our final model, the SGDClassifier, was developed and fine-tuned to capture the intricate patterns in the data. We are confident that this model is well-suited for making accurate predictions about the survivors.

**Conclusion**
Throughout this project, our approach was guided by thorough data analysis and inspired by influential resources. We successfully developed a robust predictive model, demonstrating the effectiveness of our data preprocessing, feature engineering, and model selection strategies.
